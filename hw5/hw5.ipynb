{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import csv\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.mlab as mlab\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy as sp\n",
    "import scipy.io as sio\n",
    "# import scipy.stats as stats\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from math import log2\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPAM = 'dist/spam_data.mat'\n",
    "TRAIN_CENSUS = 'hw5_census_dist/train_data.csv'\n",
    "TRAIN_TITANIC = 'hw5_titanic_dist/titanic_training.csv'\n",
    "TEST_TITANIC = 'hw5_titanic_dist/titanic_testing_data.csv' \n",
    "TEST_CENSUS = 'hw5_census_dist/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = sio.loadmat(SPAM)\n",
    "census_tdata = pd.read_csv(TRAIN_CENSUS)\n",
    "titanic_tdata = pd.read_csv(TRAIN_TITANIC)\n",
    "census_test = pd.read_csv(TEST_CENSUS)\n",
    "titanic_test = pd.read_csv(TEST_TITANIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TRAINING DATA\"\"\"\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata.drop('ticket', 1)\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Row 707 is empty in titanic_training.csv\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.dropna(how='all')\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_titanic = tv.fit_transform(titanic_tdata_filtered.to_dict(orient='records'))\n",
    "\n",
    "# \"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "# timp = Imputer()\n",
    "# imputed_titanic = timp.fit_transform(vectorized_titanic)\n",
    "\n",
    "# ttdata = pd.DataFrame(data=imputed_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata = pd.DataFrame(data=vectorized_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata['pclass'].fillna(ttdata['pclass'].mode(), inplace=True)\n",
    "ttdata['sex=male'].fillna(ttdata['sex=male'].mode(), inplace=True)\n",
    "ttdata['sex=female'].fillna(ttdata['sex=female'].mode(), inplace=True)\n",
    "ttdata['embarked'].fillna(ttdata['embarked'].mode(), inplace=True)\n",
    "\n",
    "\n",
    "ttdata['age'].fillna(int(ttdata['age'].mean()), inplace=True)\n",
    "ttdata['sibsp'].fillna(int(ttdata['sibsp'].mean()), inplace=True)\n",
    "ttdata['parch'].fillna(int(ttdata['parch'].mean()), inplace=True)\n",
    "ttdata['fare'].fillna(int(ttdata['fare'].mean()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_test_filtered = titanic_test.drop('ticket', 1)\n",
    "titanic_test_filtered = titanic_test_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_ttest = tv.fit_transform(titanic_test_filtered.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "timp = Imputer()\n",
    "timputed = timp.fit_transform(vectorized_ttest)\n",
    "\n",
    "ttestdata = pd.DataFrame(data=timputed.toarray(), columns=tv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"CENSUS TRAINING DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_census = cv.fit_transform(census_tdata.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census = cimp.fit_transform(vectorized_census)\n",
    "\n",
    "ctdata = pd.DataFrame(data=imputed_census.toarray(), columns=cv.get_feature_names(), dtype='object')\n",
    "\n",
    "\n",
    "\"\"\"CENSUS TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_ctest = cv.fit_transform(census_test.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census_test = cimp.fit_transform(vectorized_ctest)\n",
    "\n",
    "ctestdata = pd.DataFrame(data=imputed_census_test.toarray(), columns=cv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npstdata = spam_data['training_data']\n",
    "npstlabels = spam_data['training_labels']\n",
    "\n",
    "stcombo = np.append(npstdata, npstlabels.T, axis=1)\n",
    "features = [str(i) for i in range(npstdata.shape[1])]\n",
    "features.append('label')\n",
    "stdata = pd.DataFrame(data=stcombo, columns=features, dtype='object')\n",
    "\n",
    "stestdata = pd.DataFrame(data=spam_data['test_data'], columns=features[:-1], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Abstraction\n",
    "## Class InternalNode\n",
    "* ### State\n",
    "    * Node left, right\n",
    "    * split_feature [split rule]\n",
    "    * split_value [split rule]\n",
    "* ### Methods\n",
    "    * `predict(data)`\n",
    "        * given a data point, chooses left or right child based on the split rule\n",
    "        * traverses starting from this node\n",
    "    * `is_leaf() { return False }`\n",
    "\n",
    "## Class LeafNode\n",
    "* ### State\n",
    "    * label\n",
    "* ### Methods\n",
    "    * `is_leaf() { return True }`\n",
    "\n",
    "## Class DecisionTree\n",
    "* ### State\n",
    "    * root\n",
    "* ### Methods\n",
    "    * `impurity(left_label_hist, right_label_hist)`\n",
    "        * calculates the entropy of a split\n",
    "    * `segmenter(data, labels)`\n",
    "        * finds the best split rule using impurity()\n",
    "        * many different types of segmenters\n",
    "    * `train(train_data, train_labels, depth_limited)`\n",
    "        * grows the decision tree\n",
    "        * uses segmenter to find the best splits\n",
    "    * `predict(data)`\n",
    "        * given a data point, traverses the tree starting at the root\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.label\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Leaf({})'.format(self.label)\n",
    "\n",
    "class InternalNode:\n",
    "    def __init__(self, left, right, split_feature, split_value):\n",
    "        self.left, self.right = left, right\n",
    "        self.split_feature = split_feature\n",
    "        self.split_value = split_value\n",
    "\n",
    "    def predict(self, data):\n",
    "        if data[self.split_feature] < self.split_value:\n",
    "            return self.left.predict(data)\n",
    "        return self.right.predict(data)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'InternalNode({}, {})'.format(self.split_feature, self.split_value)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, root=None):\n",
    "        self.root = root\n",
    "\n",
    "    def logsp(self, x, y):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        return x * log2(x / (x + y))\n",
    "\n",
    "    def impurity(self, C, D, nC, nD):\n",
    "        c, d = nC - C, nD - D\n",
    "        return -(self.logsp(C, D) + self.logsp(D, C) + self.logsp(c, d) + self.logsp(d, c)) / (nC + nD)\n",
    "\n",
    "    def count(self, data, label):\n",
    "        nC, nD = 0, 0\n",
    "        for lbl in data[label]:\n",
    "            if lbl == 0:\n",
    "                nC += 1\n",
    "            else:\n",
    "                nD += 1\n",
    "        return nC, nD\n",
    "\n",
    "    def segmenter(self, data, label, is_random_forest=False, m=0):\n",
    "        \"\"\"\n",
    "        For splits on a feature f with a value v,\n",
    "            left will have samples with f values strictly less than v\n",
    "            right will have samples with f values greater than or equal to v\n",
    "        \"\"\"\n",
    "        if is_random_forest:\n",
    "            if m <= 0:\n",
    "                m = int(sqrt(len(data.axes[1]) - 1))\n",
    "            elif m < 1:\n",
    "                m = int((len(data.axes[1]) - 1) * m)\n",
    "            features = data.drop(label, 1).sample(m, axis=1)\n",
    "        else:\n",
    "            features = data.drop(label, 1).axes[1]\n",
    "\n",
    "        min_entropy, splitf, splitv, spliti = float('inf'), None, None, 0\n",
    "\n",
    "        for f in features:\n",
    "            sorted_data_by_f = data.sort_values(f)\n",
    "\n",
    "            iterv = sorted_data_by_f[f].__iter__()\n",
    "            iterl = sorted_data_by_f[label].__iter__()\n",
    "\n",
    "            nC, nD = self.count(sorted_data_by_f, label)\n",
    "\n",
    "            # keeps track of which value-label pair we're on\n",
    "            v, lbl, i = next(iterv), next(iterl), 0\n",
    "\n",
    "            # keeps track of class counts on LEFT\n",
    "            C, D = 0, 0\n",
    "\n",
    "            # don't check if all data lies on one side, since then this node should be a leaf (base case of train)\n",
    "            beta_iter = sorted_data_by_f.drop_duplicates(subset=f, keep='first')[f].__iter__()\n",
    "            next(beta_iter)\n",
    "\n",
    "            for beta in beta_iter:\n",
    "                try:\n",
    "                    while v != beta:\n",
    "                        if lbl == 0:\n",
    "                            C += 1\n",
    "                        else:\n",
    "                            D += 1\n",
    "                        i += 1\n",
    "                        v, lbl = next(iterv), next(iterl)\n",
    "                except StopIteration:\n",
    "                    continue\n",
    "                entropy = self.impurity(C, D, nC, nD)\n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy, splitf, splitv, spliti = entropy, f, beta, i\n",
    "            # no need to check split on max(beta)+1 since then all elements are on one split (node should be leaf)\n",
    "\n",
    "        if splitf == None:\n",
    "            return None, None, splitf, splitv #, spliti\n",
    "\n",
    "        sorted_data = data.sort_values(splitf)\n",
    "        left = sorted_data.iloc[:spliti]\n",
    "        right = sorted_data.iloc[spliti:]\n",
    "\n",
    "        return left, right, splitf, splitv #, spliti\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "        def grow_tree(train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "            labels = train_data[label].unique()\n",
    "            if depth_limited == 0 or len(labels) == 1:\n",
    "                return LeafNode(labels[0])\n",
    "\n",
    "            left_data, right_data, split_feature, split_value = self.segmenter(train_data, label, is_random_forest, m)\n",
    "\n",
    "            if left_data is None:\n",
    "                lbl = train_data[label].value_counts().argmax()\n",
    "                return LeafNode(lbl)\n",
    "\n",
    "            left = grow_tree(left_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            right = grow_tree(right_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            return InternalNode(left, right, split_feature, split_value)\n",
    "        self.root = grow_tree(train_data, label, depth_limited, is_random_forest, m)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.root.predict(data)\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n=150):\n",
    "        self.n = n\n",
    "        self.forest = []\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), m=0, bagging=0):\n",
    "        if bagging == 0:\n",
    "             bagging = len(train_data)\n",
    "        for i in range(self.n):\n",
    "            t = DecisionTree()\n",
    "            t.train(train_data.sample(bagging, replace=True), label, depth_limited, True, m)\n",
    "            self.forest.append(t)\n",
    "            if i % (self.n // 10)  == 0:\n",
    "                print(i)\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions, count0, count1 = [], 0, 0\n",
    "        for t in self.forest:\n",
    "            predictions.append(t.predict(data))\n",
    "            if predictions[-1] == 0:\n",
    "                count0 += 1\n",
    "            else:\n",
    "                count1 += 1\n",
    "        if count0 > count1:\n",
    "            return 0\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "15\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "shuffled_ttdata = ttdata.sample(frac=1)\n",
    "tvnum = int(len(shuffled_ttdata) // 10)\n",
    "vsttdata = shuffled_ttdata[:tvnum]\n",
    "tsttdata = shuffled_ttdata[tvnum:]\n",
    "\n",
    "tlabel = 'survived'\n",
    "rf = RandomForest(150)\n",
    "rf.train(tsttdata, tlabel, depth_limited=10)\n",
    "\n",
    "correct = 0\n",
    "for _, vsample in vsttdata.iterrows():\n",
    "    if rf.predict(vsample) == vsample[tlabel]:\n",
    "        correct += 1\n",
    "print(correct / len(vsttdata), correct, len(vsttdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8383838383838383 83 99\n"
     ]
    }
   ],
   "source": [
    "shuffled_ttdata = ttdata.sample(frac=1)\n",
    "tvnum = int(len(shuffled_ttdata) // 10)\n",
    "vsttdata = shuffled_ttdata[:tvnum]\n",
    "tsttdata = shuffled_ttdata[tvnum:]\n",
    "\n",
    "tlabel = 'survived'\n",
    "tdt = DecisionTree()\n",
    "tdt.train(tsttdata, tlabel)\n",
    "\n",
    "correct = 0\n",
    "for _, vsample in vsttdata.iterrows():\n",
    "    if tdt.predict(vsample) == vsample[tlabel]:\n",
    "        correct += 1\n",
    "print(correct / len(vsttdata), correct, len(vsttdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7575757575757576 75 99\n"
     ]
    }
   ],
   "source": [
    "shuffled_ttdata = ttdata.sample(frac=1)\n",
    "tvnum = int(len(shuffled_ttdata) // 10)\n",
    "vsttdata = shuffled_ttdata[:tvnum]\n",
    "tsttdata = shuffled_ttdata[tvnum:]\n",
    "\n",
    "tlabel = 'survived'\n",
    "tdt = DecisionTree()\n",
    "tdt.train(tsttdata, tlabel)\n",
    "\n",
    "correct = 0\n",
    "for _, vsample in vsttdata.iterrows():\n",
    "    if tdt.predict(vsample) == vsample[tlabel]:\n",
    "        correct += 1\n",
    "print(correct / len(vsttdata), correct, len(vsttdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_tdt = DecisionTree()\n",
    "kaggle_tdt.train(ttdata, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('titanic.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ttestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_tdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80440097799511 2632 3272\n"
     ]
    }
   ],
   "source": [
    "shuffled_ctdata = ctdata.sample(frac=1)\n",
    "cvnum = int(len(shuffled_ctdata) // 10)\n",
    "vsctdata = shuffled_ctdata[:cvnum]\n",
    "tsctdata = shuffled_ctdata[cvnum:]\n",
    "\n",
    "clabel = 'label'\n",
    "cdt = DecisionTree()\n",
    "cdt.train(tsctdata, clabel)\n",
    "\n",
    "correct = 0\n",
    "for _, vsample in vsctdata.iterrows():\n",
    "    if cdt.predict(vsample) == vsample[clabel]:\n",
    "        correct += 1\n",
    "print(correct / len(vsctdata), correct, len(vsctdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_cdt = DecisionTree()\n",
    "kaggle_cdt.train(ctdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('census.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ctestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_cdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624472573839662 1807 2370\n"
     ]
    }
   ],
   "source": [
    "shuffled_stdata = stdata.sample(frac=1)\n",
    "svnum = int(len(shuffled_stdata) // 10)\n",
    "vsstdata = shuffled_stdata[:svnum]\n",
    "tsstdata = shuffled_stdata[svnum:]\n",
    "\n",
    "slabel = 'label'\n",
    "sdt = DecisionTree()\n",
    "sdt.train(tsstdata, slabel)\n",
    "\n",
    "correct = 0\n",
    "for _, vsample in vsstdata.iterrows():\n",
    "    if sdt.predict(vsample) == vsample[clabel]:\n",
    "        correct += 1\n",
    "print(correct / len(vsstdata), correct, len(vsstdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_sdt = DecisionTree()\n",
    "kaggle_sdt.train(stdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('spam.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 0\n",
    "for _, vsample in stestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_sdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 32724 32724\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "clabel = 'label'\n",
    "for _, vsample in ctdata.iterrows():\n",
    "    if kaggle_cdt.predict(vsample) == vsample[clabel]:\n",
    "        correct += 1\n",
    "print(correct / len(ctdata), correct, len(ctdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_titanic = ttdata[:30]\n",
    "small_tdt = DecisionTree()\n",
    "# small_titanic['survived'].unique()\n",
    "small_tdt.train(small_titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "p = small_tdt.predict(ttdata.iloc[345])\n",
    "print(p, ttdata['survived'][345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# q = []\n",
    "# q.append(small_tdt.root)\n",
    "# while len(q) > 0:\n",
    "#     n = q.pop(0)\n",
    "#     if not n.is_leaf():\n",
    "#         print(n.split_feature, n.split_value, '\\n')\n",
    "#         q.append(n.left)\n",
    "#         q.append(n.right)\n",
    "#     else:\n",
    "#         print('label: ', n.label, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalNode(banana, 4)\n",
      "InternalNode(apple, 1)\n",
      "Leaf(0)\n",
      "Leaf(0)\n",
      "Leaf(1)\n"
     ]
    }
   ],
   "source": [
    "k, a, b = 'survived', 'apple', 'banana'\n",
    "d = [{k: 0, a: 0, b: 1},\n",
    "     {k: 0, a: 1, b: 77},\n",
    "     {k: 0, a: 1, b: 4},\n",
    "     {k: 1, a: 1, b: 1}, \n",
    "     {k: 1, a: 1, b: 2}]\n",
    "\n",
    "# d = [{k: 0, a: 0, b: 1},\n",
    "#      {k: 1, a: 0, b: 1},\n",
    "#      {k: 1, a: 0, b: 1}]\n",
    "\n",
    "dfd = pd.DataFrame(d)\n",
    "tdt = DecisionTree()\n",
    "tdt.train(dfd, k)\n",
    "q = []\n",
    "q.append(tdt.root)\n",
    "while len(q) != 0:\n",
    "    n = q.pop(0)\n",
    "    print(n)\n",
    "    if not n.is_leaf():\n",
    "        q.append(n.left)\n",
    "        q.append(n.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first_name last_name  age  preTestScore  postTestScore\n",
      "0      Jason    Miller   42             4             25\n",
      "1      Jason    Miller   42             4             25\n",
      "2       Tina       Ali   36            31             57\n",
      "3       Jake    Milner   24             2             62\n",
      "4        Amy     Cooze   73             3             70\n",
      "5       Zach    Miller    4           100            100\n",
      "  first_name last_name  age  preTestScore  postTestScore\n",
      "0      Jason    Miller   42             4             25\n",
      "2       Tina       Ali   36            31             57\n",
      "3       Jake    Milner   24             2             62\n",
      "4        Amy     Cooze   73             3             70\n",
      "5       Zach    Miller    4           100            100\n"
     ]
    }
   ],
   "source": [
    "raw_data = {'first_name': ['Jason', 'Jason', 'Tina', 'Jake', 'Amy', 'Zach'],\n",
    "        'last_name': ['Miller', 'Miller', 'Ali', 'Milner', 'Cooze', 'Miller'],\n",
    "        'age': [42, 42, 36, 24, 73, 4],\n",
    "        'preTestScore': [4, 4, 31, 2, 3, 100],\n",
    "        'postTestScore': [25, 25, 57, 62, 70, 100]}\n",
    "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])\n",
    "print(df)\n",
    "print(df.drop_duplicates(subset='first_name', keep='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
