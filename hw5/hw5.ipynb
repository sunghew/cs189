{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.mlab as mlab\n",
    "# import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import operator\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from math import log2\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPAM = 'dist/spam_data.mat'\n",
    "TRAIN_CENSUS = 'hw5_census_dist/train_data.csv'\n",
    "TRAIN_TITANIC = 'hw5_titanic_dist/titanic_training.csv'\n",
    "TEST_TITANIC = 'hw5_titanic_dist/titanic_testing_data.csv' \n",
    "TEST_CENSUS = 'hw5_census_dist/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = sio.loadmat(SPAM)\n",
    "census_tdata = pd.read_csv(TRAIN_CENSUS)\n",
    "titanic_tdata = pd.read_csv(TRAIN_TITANIC)\n",
    "census_test = pd.read_csv(TEST_CENSUS)\n",
    "titanic_test = pd.read_csv(TEST_TITANIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 1 & 2\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TRAINING DATA\"\"\"\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata.drop('ticket', 1)\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Row 707 is empty in titanic_training.csv\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.dropna(how='all')\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_titanic = tv.fit_transform(titanic_tdata_filtered.to_dict(orient='records'))\n",
    "\n",
    "# \"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "# timp = Imputer()\n",
    "# imputed_titanic = timp.fit_transform(vectorized_titanic)\n",
    "\n",
    "# ttdata = pd.DataFrame(data=imputed_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata = pd.DataFrame(data=vectorized_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata['pclass'].fillna(ttdata['pclass'].mode(), inplace=True)\n",
    "ttdata['sex=male'].fillna(ttdata['sex=male'].mode(), inplace=True)\n",
    "ttdata['sex=female'].fillna(ttdata['sex=female'].mode(), inplace=True)\n",
    "ttdata['embarked'].fillna(ttdata['embarked'].mode(), inplace=True)\n",
    "\n",
    "\n",
    "ttdata['age'].fillna(int(ttdata['age'].mean()), inplace=True)\n",
    "ttdata['sibsp'].fillna(int(ttdata['sibsp'].mean()), inplace=True)\n",
    "ttdata['parch'].fillna(int(ttdata['parch'].mean()), inplace=True)\n",
    "ttdata['fare'].fillna(int(ttdata['fare'].mean()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_test_filtered = titanic_test.drop('ticket', 1)\n",
    "titanic_test_filtered = titanic_test_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_ttest = tv.fit_transform(titanic_test_filtered.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "timp = Imputer()\n",
    "timputed = timp.fit_transform(vectorized_ttest)\n",
    "\n",
    "ttestdata = pd.DataFrame(data=timputed.toarray(), columns=tv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"CENSUS TRAINING DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_census = cv.fit_transform(census_tdata.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census = cimp.fit_transform(vectorized_census)\n",
    "\n",
    "ctdata = pd.DataFrame(data=imputed_census.toarray(), columns=cv.get_feature_names(), dtype='object')\n",
    "\n",
    "\n",
    "\"\"\"CENSUS TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_ctest = cv.fit_transform(census_test.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census_test = cimp.fit_transform(vectorized_ctest)\n",
    "\n",
    "ctestdata = pd.DataFrame(data=imputed_census_test.toarray(), columns=cv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npstdata = spam_data['training_data']\n",
    "npstlabels = spam_data['training_labels']\n",
    "\n",
    "stcombo = np.append(npstdata, npstlabels.T, axis=1)\n",
    "features = ['pain', 'private', 'bank', 'money', 'drug', 'spam', 'prescription', 'creative', 'height', \n",
    "            'featured', 'differ', 'width', 'other', 'energy', 'business', 'message', 'volumes', 'revision', \n",
    "            'path', 'meter', 'memo', 'planning', 'pleased', 'record', 'out', ';', '$', '#', '!', '(', '[', '&']\n",
    "features.append('label')\n",
    "stdata = pd.DataFrame(data=stcombo, columns=features, dtype='object')\n",
    "\n",
    "stestdata = pd.DataFrame(data=spam_data['test_data'], columns=features[:-1], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Abstraction\n",
    "## Class InternalNode\n",
    "* ### State\n",
    "    * Node left, right\n",
    "    * split_feature [split rule]\n",
    "    * split_value [split rule]\n",
    "* ### Methods\n",
    "    * `predict(data)`\n",
    "        * given a data point, chooses left or right child based on the split rule\n",
    "        * traverses starting from this node\n",
    "    * `is_leaf() { return False }`\n",
    "\n",
    "## Class LeafNode\n",
    "* ### State\n",
    "    * label\n",
    "* ### Methods\n",
    "    * `is_leaf() { return True }`\n",
    "\n",
    "## Class DecisionTree\n",
    "* ### State\n",
    "    * root\n",
    "* ### Methods\n",
    "    * `impurity(left_label_hist, right_label_hist)`\n",
    "        * calculates the entropy of a split\n",
    "    * `segmenter(data, labels)`\n",
    "        * finds the best split rule using impurity()\n",
    "        * many different types of segmenters\n",
    "    * `train(train_data, train_labels, depth_limited)`\n",
    "        * grows the decision tree\n",
    "        * uses segmenter to find the best splits\n",
    "    * `predict(data)`\n",
    "        * given a data point, traverses the tree starting at the root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Random Forest Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        if verbose:\n",
    "            print(self)\n",
    "        return self.label\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Leaf({})'.format(self.label)\n",
    "\n",
    "class InternalNode:\n",
    "    def __init__(self, left, right, split_feature, split_value):\n",
    "        self.left, self.right = left, right\n",
    "        self.split_feature = split_feature\n",
    "        self.split_value = split_value\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        if data[self.split_feature] < self.split_value:\n",
    "            if verbose:\n",
    "                print('Feature {}: {} < {} -> left'.format(self.split_feature, \n",
    "                                                           data[self.split_feature], self.split_value))\n",
    "            return self.left.predict(data, verbose)\n",
    "        if verbose:\n",
    "            print('Feature {}: {} >= {} -> right'.format(self.split_feature, \n",
    "                                                       data[self.split_feature], self.split_value))\n",
    "        return self.right.predict(data, verbose)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'InternalNode({}, {})'.format(self.split_feature, self.split_value)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, root=None):\n",
    "        self.root = root\n",
    "\n",
    "    def logsp(self, x, y):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        return x * log2(x / (x + y))\n",
    "\n",
    "    def impurity(self, C, D, nC, nD):\n",
    "        c, d = nC - C, nD - D\n",
    "        return -(self.logsp(C, D) + self.logsp(D, C) + self.logsp(c, d) + self.logsp(d, c)) / (nC + nD)\n",
    "\n",
    "    def count(self, data, label):\n",
    "        nC, nD = 0, 0\n",
    "        for lbl in data[label]:\n",
    "            if lbl == 0:\n",
    "                nC += 1\n",
    "            else:\n",
    "                nD += 1\n",
    "        return nC, nD\n",
    "\n",
    "    def segmenter(self, data, label, is_random_forest=False, m=0):\n",
    "        \"\"\"\n",
    "        For splits on a feature f with a value v,\n",
    "            left will have samples with f values strictly less than v\n",
    "            right will have samples with f values greater than or equal to v\n",
    "        \"\"\"\n",
    "        if is_random_forest:\n",
    "            if m <= 0:\n",
    "                m = int(sqrt(len(data.axes[1]) - 1))\n",
    "            elif m < 1:\n",
    "                m = int((len(data.axes[1]) - 1) * m)\n",
    "            features = data.drop(label, 1).sample(m, axis=1)\n",
    "        else:\n",
    "            features = data.drop(label, 1).axes[1]\n",
    "\n",
    "        min_entropy, splitf, splitv, spliti = float('inf'), None, None, 0\n",
    "\n",
    "        for f in features:\n",
    "            sorted_data_by_f = data.sort_values(f)\n",
    "\n",
    "            iterv = sorted_data_by_f[f].__iter__()\n",
    "            iterl = sorted_data_by_f[label].__iter__()\n",
    "\n",
    "            nC, nD = self.count(sorted_data_by_f, label)\n",
    "\n",
    "            # keeps track of which value-label pair we're on\n",
    "            v, lbl, i = next(iterv), next(iterl), 0\n",
    "\n",
    "            # keeps track of class counts on LEFT\n",
    "            C, D = 0, 0\n",
    "\n",
    "            # don't check if all data lies on one side, since then this node should be a leaf (base case of train)\n",
    "            beta_iter = sorted_data_by_f.drop_duplicates(subset=f, keep='first')[f].__iter__()\n",
    "            next(beta_iter)\n",
    "\n",
    "            for beta in beta_iter:\n",
    "                try:\n",
    "                    while v != beta:\n",
    "                        if lbl == 0:\n",
    "                            C += 1\n",
    "                        else:\n",
    "                            D += 1\n",
    "                        i += 1\n",
    "                        v, lbl = next(iterv), next(iterl)\n",
    "                except StopIteration:\n",
    "                    continue\n",
    "                entropy = self.impurity(C, D, nC, nD)\n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy, splitf, splitv, spliti = entropy, f, beta, i\n",
    "            # no need to check split on max(beta)+1 since then all elements are on one split (node should be leaf)\n",
    "\n",
    "        if splitf == None:\n",
    "            return None, None, splitf, splitv #, spliti\n",
    "\n",
    "        sorted_data = data.sort_values(splitf)\n",
    "        left = sorted_data.iloc[:spliti]\n",
    "        right = sorted_data.iloc[spliti:]\n",
    "\n",
    "        return left, right, splitf, splitv #, spliti\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "        def grow_tree(train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "            labels = train_data[label].unique()\n",
    "            if depth_limited == 0 or len(labels) == 1:\n",
    "                return LeafNode(labels[0])\n",
    "\n",
    "            left_data, right_data, split_feature, split_value = self.segmenter(train_data, label, is_random_forest, m)\n",
    "\n",
    "            if left_data is None:\n",
    "                lbl = train_data[label].value_counts().argmax()\n",
    "                return LeafNode(lbl)\n",
    "\n",
    "            left = grow_tree(left_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            right = grow_tree(right_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            return InternalNode(left, right, split_feature, split_value)\n",
    "        self.root = grow_tree(train_data, label, depth_limited, is_random_forest, m)\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        return self.root.predict(data, verbose)\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n=150):\n",
    "        self.n = n\n",
    "        self.forest = []\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), m=0, bagging=0):\n",
    "        if bagging == 0:\n",
    "             bagging = len(train_data)\n",
    "        for i in range(self.n):\n",
    "            t = DecisionTree()\n",
    "            t.train(train_data.sample(bagging, replace=True), label, depth_limited, True, m)\n",
    "            self.forest.append(t)\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions, count0, count1 = [], 0, 0\n",
    "        for t in self.forest:\n",
    "            predictions.append(t.predict(data))\n",
    "            if predictions[-1] == 0:\n",
    "                count0 += 1\n",
    "            else:\n",
    "                count1 += 1\n",
    "        if count0 > count1:\n",
    "            return 0\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Implementation Details\n",
    "(a) Categorical features were mapped to binary variables as suggested in Appendix 1.a. For the Titanic dataset, missing values of categorical data were replaced with the mode and for continuous features with the mean while for all other datasets missing values were replaced with just the mean.\n",
    "\n",
    "(b) The stopping criteria used was having pure nodes (all samples in a node belonging to the same class) or having an empty child (this would be the left); however, a depth-limited criteria was also implemented and used for random forests.\n",
    "\n",
    "(c) Nothing special was done to speed up training.\n",
    "\n",
    "(d) The `segmenter` method of `DecisionTree` was modified to sample features for `RandomForest`. A `RandomForest` class was created and held a list of `DecisionTree`. Each `DecisionTree` of the list was trained with bagging, and bagging was done in `RandomForest#train`.\n",
    "\n",
    "(e) Nothing out of the ordinary was implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Performance Evaluation\n",
    "Kaggle username: cschon\n",
    "\n",
    "#### Titanic\n",
    "* Decision Tree\n",
    "    * Training: 0.9737\n",
    "    * Validation: 0.7755\n",
    "* Random Forest\n",
    "    * Training: 0.8632\n",
    "    * Validation: 0.8163\n",
    "* Kaggle (Random Forest): \t0.80645\n",
    "\n",
    "#### Census\n",
    "* Decision Tree\n",
    "    * Training: 0.8296\n",
    "    * Validation: 0.8142\n",
    "* Random Forest\n",
    "    * Training: 0.8607\n",
    "    * Validation: 0.8551\n",
    "* Kaggle (Decision Tree): \t0.81338\n",
    "\n",
    "#### Spam\n",
    "* Decision Tree\n",
    "    * Training: 0.7223\n",
    "    * Validation: 0.7325\n",
    "* Random Forest\n",
    "    * Training: 0.7924\n",
    "    * Validation: 0.7882\n",
    "* Kaggle (Decision Tree): 0.76840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(data, label, model, depth_limited=float('inf'), n=None):\n",
    "    shuffled_data = data.sample(frac=1)\n",
    "    tvnum = int(len(shuffled_data) // 20)\n",
    "    vdata = shuffled_data[:tvnum]\n",
    "    tdata = shuffled_data[tvnum:]\n",
    "    \n",
    "    if n == None:\n",
    "        m = model()\n",
    "    else:\n",
    "        m = model(n)\n",
    "    m.train(tdata, label, depth_limited)\n",
    "    return m, vdata, tdata\n",
    "    \n",
    "def evaluate(data, label, model, depth_limited=float('inf'), n=None):\n",
    "    m, vdata, tdata = train(data, label, model, depth_limited, n)\n",
    "\n",
    "    vcorrect = 0\n",
    "    for _, vsample in vdata.iterrows():\n",
    "        if m.predict(vsample) == vsample[label]:\n",
    "            vcorrect += 1\n",
    "            \n",
    "    tcorrect = 0      \n",
    "    for _, tsample in tdata.iterrows():\n",
    "        if m.predict(tsample) == tsample[label]:\n",
    "            tcorrect += 1\n",
    "            \n",
    "    return vcorrect / len(vdata), tcorrect / len(tdata), m\n",
    "\n",
    "def print_evaluate(data, label, model, depth_limited=float('inf')):\n",
    "    v, t, m = evaluate(data, label, model, depth_limited)\n",
    "    print('Training Accuracy: {}\\nValidation Accuracy: {}'.format(t, v))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9736842105263158\n",
      "Validation Accuracy: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "tdt = print_evaluate(ttdata, 'survived', DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8296448790530108\n",
      "Validation Accuracy: 0.8141809290953546\n"
     ]
    }
   ],
   "source": [
    "cdt = print_evaluate(ctdata, 'label', DecisionTree, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7222987076431141\n",
      "Validation Accuracy: 0.7324894514767932\n"
     ]
    }
   ],
   "source": [
    "sdt = print_evaluate(stdata, 'label', DecisionTree, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8631578947368421\n",
      "Validation Accuracy: 0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "trf = print_evaluate(ttdata, 'survived', RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8606536284096757\n",
      "Validation Accuracy: 0.8551344743276283\n"
     ]
    }
   ],
   "source": [
    "crf = print_evaluate(ctdata, 'label', RandomForest, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7923790913531998\n",
      "Validation Accuracy: 0.7881856540084389\n"
     ]
    }
   ],
   "source": [
    "srf = print_evaluate(stdata, 'label', RandomForest, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_trf = RandomForest()\n",
    "kaggle_trf.train(ttdata, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('titanic.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ttestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_trf.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_cdt = DecisionTree()\n",
    "kaggle_cdt.train(ctdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('census.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ctestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_cdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_sdt = DecisionTree()\n",
    "kaggle_sdt.train(stdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('spam.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 0\n",
    "for _, vsample in stestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_sdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Spam Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) No other features or feature transformations were used.\n",
    "\n",
    "(b) Decision Tree Splits\n",
    "\n",
    "(\"!\") < 1  \n",
    "(\"(\") >= 1  \n",
    "(\"money\") < 1  \n",
    "(\"featured\") < 1  \n",
    "(\"energy\") < 1  \n",
    "(\"$\") < 1  \n",
    "(\"spam\") < 1  \n",
    "(\"bank\") < 2  \n",
    "(\"prescription\") < 1  \n",
    "(\"[\") < 1  \n",
    "Ham (class 0)  \n",
    "\n",
    "(\"!\") >= 1  \n",
    "(\"energy\") < 1  \n",
    "(\"money\") < 1  \n",
    "(\"(\") < 1  \n",
    "(\"!\") < 33  \n",
    "(\"prescription\") < 1  \n",
    "(\"$\") >= 1  \n",
    "(\"volumes\") < 1  \n",
    "(\"&\") < 4  \n",
    "(\"meter\") < 1  \n",
    "Ham (class 1)  \n",
    "\n",
    "(c) Random Forest Most common split made at root node of trees\n",
    "\n",
    "(\"money\"), 1 (29 trees)  \n",
    "(\"!\"), 1 (20 trees)  \n",
    "(\"energy\"), 1 (18 trees)  \n",
    "(\"(\"), 1 (17 trees)  \n",
    "(\"$\"), 1 (12 trees)  \n",
    "(\"featured\"), 1 (10 trees)  \n",
    "(\"&\"), 1 (8 trees)  \n",
    "(\"prescription\"), 1 (7 trees)  \n",
    "(\"meter\"), 1 (7 trees)  \n",
    "(\"private\"), 1 (3 trees)  \n",
    "(\"volumes\"), 1 (3 trees)  \n",
    "(\"pain\"), 1 (3 trees)  \n",
    "(\"memo\"), 1 (3 trees)  \n",
    "(\";\"), 2 (2 trees)  \n",
    "(\"spam\"), 1 (2 trees)  \n",
    "(\";\"), 4 (2 trees)  \n",
    "(\"creative\"), 1 (2 trees)  \n",
    "(\"drug\"), 1 (1 trees)  \n",
    "(\"differ\"), 1 (1 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = stdata.sample(10)\n",
    "ham = samples[samples['label'] == 0].iloc[0]\n",
    "spam = samples[samples['label'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0] \n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(ham), '\\n')\n",
    "print(list(spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature !: 0.0 < 1.0 -> left\n",
      "Feature (: 1.0 >= 1.0 -> right\n",
      "Feature money: 0.0 < 1.0 -> left\n",
      "Feature featured: 0.0 < 1.0 -> left\n",
      "Feature energy: 0.0 < 1.0 -> left\n",
      "Feature $: 0.0 < 1.0 -> left\n",
      "Feature spam: 0.0 < 1.0 -> left\n",
      "Feature bank: 0.0 < 2.0 -> left\n",
      "Feature prescription: 0.0 < 1.0 -> left\n",
      "Feature [: 0.0 < 1.0 -> left\n",
      "Leaf(0.0)\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(sdt.predict(ham, True), ham['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature !: 1.0 >= 1.0 -> right\n",
      "Feature energy: 0.0 < 1.0 -> left\n",
      "Feature money: 0.0 < 1.0 -> left\n",
      "Feature (: 0.0 < 1.0 -> left\n",
      "Feature !: 1.0 < 33.0 -> left\n",
      "Feature prescription: 0.0 < 1.0 -> left\n",
      "Feature $: 1.0 >= 1.0 -> right\n",
      "Feature volumes: 0.0 < 1.0 -> left\n",
      "Feature &: 1.0 < 4.0 -> left\n",
      "Feature meter: 0.0 < 1.0 -> left\n",
      "Leaf(1.0)\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(sdt.predict(spam, True), spam['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def root_splits(rf):\n",
    "    root_splits = {}\n",
    "    for t in rf.forest:\n",
    "        pair = (t.root.split_feature, t.root.split_value)\n",
    "        if pair not in root_splits:\n",
    "            root_splits[pair] = 0\n",
    "        root_splits[pair] += 1\n",
    "    \n",
    "    split_ranking = sorted(root_splits.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for s in split_ranking:\n",
    "        print('(\\\"{}\\\"), {} ({} trees)'.format(s[0][0], int(s[0][1]), s[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"money\"), 1 (29 trees)\n",
      "(\"!\"), 1 (20 trees)\n",
      "(\"energy\"), 1 (18 trees)\n",
      "(\"(\"), 1 (17 trees)\n",
      "(\"$\"), 1 (12 trees)\n",
      "(\"featured\"), 1 (10 trees)\n",
      "(\"&\"), 1 (8 trees)\n",
      "(\"prescription\"), 1 (7 trees)\n",
      "(\"meter\"), 1 (7 trees)\n",
      "(\"private\"), 1 (3 trees)\n",
      "(\"volumes\"), 1 (3 trees)\n",
      "(\"pain\"), 1 (3 trees)\n",
      "(\"memo\"), 1 (3 trees)\n",
      "(\";\"), 2 (2 trees)\n",
      "(\"spam\"), 1 (2 trees)\n",
      "(\";\"), 4 (2 trees)\n",
      "(\"creative\"), 1 (2 trees)\n",
      "(\"drug\"), 1 (1 trees)\n",
      "(\"differ\"), 1 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "root_splits(srf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 6: Census Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ctdata.sample(10)\n",
    "poor = samples[samples['label'] == 0].iloc[0]\n",
    "rich = samples[samples['label'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature marital-status=Married-civ-spouse: 0.0 < 1.0 -> left\n",
      "Feature capital-gain: 0.0 < 7262.0 -> left\n",
      "Feature education-num: 10.0 < 13.0 -> left\n",
      "Feature age: 30.0 >= 27.0 -> right\n",
      "Feature hours-per-week: 40.0 < 41.0 -> left\n",
      "Feature capital-loss: 0.0 < 2231.0 -> left\n",
      "Feature occupation=Prof-specialty: 0.0 < 1.0 -> left\n",
      "Feature occupation=Exec-managerial: 0.0 < 1.0 -> left\n",
      "Feature sex=Female: 0.0 < 1.0 -> left\n",
      "Feature age: 30.0 < 42.0 -> left\n",
      "Leaf(0.0)\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(cdt.predict(poor, True), poor['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature marital-status=Married-civ-spouse: 1.0 >= 1.0 -> right\n",
      "Feature education-num: 13.0 >= 12.0 -> right\n",
      "Feature capital-gain: 0.0 < 5178.0 -> left\n",
      "Feature capital-loss: 0.0 < 1825.0 -> left\n",
      "Feature hours-per-week: 40.0 >= 31.0 -> right\n",
      "Feature age: 31.0 < 34.0 -> left\n",
      "Feature age: 31.0 >= 28.0 -> right\n",
      "Feature occupation=Exec-managerial: 0.0 < 1.0 -> left\n",
      "Feature education=Assoc-acdm: 0.0 < 1.0 -> left\n",
      "Feature native-country=United-States: 1.0 >= 1.0 -> right\n",
      "Leaf(1.0)\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(cdt.predict(rich, True), rich['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"marital-status=Married-civ-spouse\"), 1 (12 trees)\n",
      "(\"relationship=Husband\"), 1 (12 trees)\n",
      "(\"education-num\"), 13 (11 trees)\n",
      "(\"marital-status=Never-married\"), 1 (10 trees)\n",
      "(\"relationship=Own-child\"), 1 (9 trees)\n",
      "(\"relationship=Not-in-family\"), 1 (9 trees)\n",
      "(\"capital-gain\"), 7298 (9 trees)\n",
      "(\"sex=Male\"), 1 (7 trees)\n",
      "(\"age\"), 28 (7 trees)\n",
      "(\"occupation=Other-service\"), 1 (7 trees)\n",
      "(\"sex=Female\"), 1 (6 trees)\n",
      "(\"education=Masters\"), 1 (5 trees)\n",
      "(\"age\"), 29 (5 trees)\n",
      "(\"education=Bachelors\"), 1 (5 trees)\n",
      "(\"education=Doctorate\"), 1 (4 trees)\n",
      "(\"marital-status=Divorced\"), 1 (4 trees)\n",
      "(\"relationship=Unmarried\"), 1 (3 trees)\n",
      "(\"capital-loss\"), 1825 (3 trees)\n",
      "(\"capital-gain\"), 5178 (3 trees)\n",
      "(\"occupation=Prof-specialty\"), 1 (3 trees)\n",
      "(\"hours-per-week\"), 42 (2 trees)\n",
      "(\"occupation=Adm-clerical\"), 1 (2 trees)\n",
      "(\"hours-per-week\"), 41 (2 trees)\n",
      "(\"marital-status=Separated\"), 1 (1 trees)\n",
      "(\"education=10th\"), 1 (1 trees)\n",
      "(\"occupation=Exec-managerial\"), 1 (1 trees)\n",
      "(\"education=HS-grad\"), 1 (1 trees)\n",
      "(\"education-num\"), 12 (1 trees)\n",
      "(\"education=Prof-school\"), 1 (1 trees)\n",
      "(\"relationship=Wife\"), 1 (1 trees)\n",
      "(\"occupation=Farming-fishing\"), 1 (1 trees)\n",
      "(\"workclass=Self-emp-inc\"), 1 (1 trees)\n",
      "(\"race=White\"), 1 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "root_splits(crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7: Titanic Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "samples = ttdata.sample(10)\n",
    "died = samples[samples['survived'] == 0].iloc[0]\n",
    "lived = samples[samples['survived'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sex=female: 1.0 >= 1.0 -> right\n",
      "Feature pclass: 3.0 >= 3.0 -> right\n",
      "Feature fare: 27.9 >= 23.45 -> right\n",
      "Feature fare: 27.9 < 31.3875 -> left\n",
      "Leaf(0.0)\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(tdt.predict(died, True), died['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sex=female: 1.0 >= 1.0 -> right\n",
      "Feature pclass: 2.0 < 3.0 -> left\n",
      "Feature embarked=S: 1.0 >= 1.0 -> right\n",
      "Feature fare: 23.0 < 26.25 -> left\n",
      "Feature age: 20.0 < 22.0 -> left\n",
      "Leaf(1.0)\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(tdt.predict(lived, True), died['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"sex=male\"), 1 (45 trees)\n",
      "(\"sex=female\"), 1 (35 trees)\n",
      "(\"pclass\"), 3 (20 trees)\n",
      "(\"parch\"), 1 (10 trees)\n",
      "(\"embarked=C\"), 1 (9 trees)\n",
      "(\"fare\"), 15 (6 trees)\n",
      "(\"fare\"), 15 (4 trees)\n",
      "(\"age\"), 10 (3 trees)\n",
      "(\"sibsp\"), 4 (3 trees)\n",
      "(\"pclass\"), 2 (2 trees)\n",
      "(\"embarked=S\"), 1 (2 trees)\n",
      "(\"fare\"), 12 (2 trees)\n",
      "(\"fare\"), 11 (2 trees)\n",
      "(\"fare\"), 75 (1 trees)\n",
      "(\"sibsp\"), 1 (1 trees)\n",
      "(\"age\"), 7 (1 trees)\n",
      "(\"age\"), 2 (1 trees)\n",
      "(\"fare\"), 9 (1 trees)\n",
      "(\"age\"), 11 (1 trees)\n",
      "(\"fare\"), 9 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "root_splits(trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
