{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import operator\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from math import log2\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPAM = 'dist/spam_data.mat'\n",
    "TRAIN_CENSUS = 'hw5_census_dist/train_data.csv'\n",
    "TRAIN_TITANIC = 'hw5_titanic_dist/titanic_training.csv'\n",
    "TEST_TITANIC = 'hw5_titanic_dist/titanic_testing_data.csv' \n",
    "TEST_CENSUS = 'hw5_census_dist/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = sio.loadmat(SPAM)\n",
    "census_tdata = pd.read_csv(TRAIN_CENSUS)\n",
    "titanic_tdata = pd.read_csv(TRAIN_TITANIC)\n",
    "census_test = pd.read_csv(TEST_CENSUS)\n",
    "titanic_test = pd.read_csv(TEST_TITANIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 1 & 2\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TRAINING DATA\"\"\"\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata.drop('ticket', 1)\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Row 707 is empty in titanic_training.csv\"\"\"\n",
    "titanic_tdata_filtered = titanic_tdata_filtered.dropna(how='all')\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_titanic = tv.fit_transform(titanic_tdata_filtered.to_dict(orient='records'))\n",
    "\n",
    "# \"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "# timp = Imputer()\n",
    "# imputed_titanic = timp.fit_transform(vectorized_titanic)\n",
    "\n",
    "# ttdata = pd.DataFrame(data=imputed_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata = pd.DataFrame(data=vectorized_titanic.toarray(), columns=tv.get_feature_names(), dtype='object')\n",
    "\n",
    "ttdata['pclass'].fillna(ttdata['pclass'].mode(), inplace=True)\n",
    "ttdata['sex=male'].fillna(ttdata['sex=male'].mode(), inplace=True)\n",
    "ttdata['sex=female'].fillna(ttdata['sex=female'].mode(), inplace=True)\n",
    "ttdata['embarked'].fillna(ttdata['embarked'].mode(), inplace=True)\n",
    "\n",
    "\n",
    "ttdata['age'].fillna(int(ttdata['age'].mean()), inplace=True)\n",
    "ttdata['sibsp'].fillna(int(ttdata['sibsp'].mean()), inplace=True)\n",
    "ttdata['parch'].fillna(int(ttdata['parch'].mean()), inplace=True)\n",
    "ttdata['fare'].fillna(int(ttdata['fare'].mean()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TITANIC TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Removed ticket and cabin features\"\"\"\n",
    "titanic_test_filtered = titanic_test.drop('ticket', 1)\n",
    "titanic_test_filtered = titanic_test_filtered.drop('cabin', 1)\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "tv = DictVectorizer()\n",
    "vectorized_ttest = tv.fit_transform(titanic_test_filtered.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "timp = Imputer()\n",
    "timputed = timp.fit_transform(vectorized_ttest)\n",
    "\n",
    "ttestdata = pd.DataFrame(data=timputed.toarray(), columns=tv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"CENSUS TRAINING DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_census = cv.fit_transform(census_tdata.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census = cimp.fit_transform(vectorized_census)\n",
    "\n",
    "ctdata = pd.DataFrame(data=imputed_census.toarray(), columns=cv.get_feature_names(), dtype='object')\n",
    "\n",
    "\n",
    "\"\"\"CENSUS TEST DATA\"\"\"\n",
    "\n",
    "\"\"\"Map categories to binary variables [1(a)]\"\"\"\n",
    "cv = DictVectorizer()\n",
    "vectorized_ctest = cv.fit_transform(census_test.to_dict(orient='records'))\n",
    "\n",
    "\"\"\"Replaced unknown values with mean of features [2(b)]\"\"\"\n",
    "cimp = Imputer()\n",
    "imputed_census_test = cimp.fit_transform(vectorized_ctest)\n",
    "\n",
    "ctestdata = pd.DataFrame(data=imputed_census_test.toarray(), columns=cv.get_feature_names(), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npstdata = spam_data['training_data']\n",
    "npstlabels = spam_data['training_labels']\n",
    "\n",
    "stcombo = np.append(npstdata, npstlabels.T, axis=1)\n",
    "features = ['pain', 'private', 'bank', 'money', 'drug', 'spam', 'prescription', 'creative', 'height', \n",
    "            'featured', 'differ', 'width', 'other', 'energy', 'business', 'message', 'volumes', 'revision', \n",
    "            'path', 'meter', 'memo', 'planning', 'pleased', 'record', 'out', ';', '$', '#', '!', '(', '[', '&']\n",
    "features.append('label')\n",
    "stdata = pd.DataFrame(data=stcombo, columns=features, dtype='object')\n",
    "\n",
    "stestdata = pd.DataFrame(data=spam_data['test_data'], columns=features[:-1], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Abstraction\n",
    "## Class InternalNode\n",
    "* ### State\n",
    "    * Node left, right\n",
    "    * split_feature [split rule]\n",
    "    * split_value [split rule]\n",
    "* ### Methods\n",
    "    * `predict(data)`\n",
    "        * given a data point, chooses left or right child based on the split rule\n",
    "        * traverses starting from this node\n",
    "    * `is_leaf() { return False }`\n",
    "\n",
    "## Class LeafNode\n",
    "* ### State\n",
    "    * label\n",
    "* ### Methods\n",
    "    * `is_leaf() { return True }`\n",
    "\n",
    "## Class DecisionTree\n",
    "* ### State\n",
    "    * root\n",
    "* ### Methods\n",
    "    * `impurity(left_label_hist, right_label_hist)`\n",
    "        * calculates the entropy of a split\n",
    "    * `segmenter(data, labels)`\n",
    "        * finds the best split rule using impurity()\n",
    "        * many different types of segmenters\n",
    "    * `train(train_data, train_labels, depth_limited)`\n",
    "        * grows the decision tree\n",
    "        * uses segmenter to find the best splits\n",
    "    * `predict(data)`\n",
    "        * given a data point, traverses the tree starting at the root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Random Forest Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        if verbose:\n",
    "            print(self)\n",
    "        return self.label\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Leaf({})'.format(self.label)\n",
    "\n",
    "class InternalNode:\n",
    "    def __init__(self, left, right, split_feature, split_value):\n",
    "        self.left, self.right = left, right\n",
    "        self.split_feature = split_feature\n",
    "        self.split_value = split_value\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        if data[self.split_feature] < self.split_value:\n",
    "            if verbose:\n",
    "                print('Feature {}: {} < {} -> left'.format(self.split_feature, \n",
    "                                                           data[self.split_feature], self.split_value))\n",
    "            return self.left.predict(data, verbose)\n",
    "        if verbose:\n",
    "            print('Feature {}: {} >= {} -> right'.format(self.split_feature, \n",
    "                                                       data[self.split_feature], self.split_value))\n",
    "        return self.right.predict(data, verbose)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'InternalNode({}, {})'.format(self.split_feature, self.split_value)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, root=None):\n",
    "        self.root = root\n",
    "\n",
    "    def logsp(self, x, y):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        return x * log2(x / (x + y))\n",
    "\n",
    "    def impurity(self, C, D, nC, nD):\n",
    "        c, d = nC - C, nD - D\n",
    "        return -(self.logsp(C, D) + self.logsp(D, C) + self.logsp(c, d) + self.logsp(d, c)) / (nC + nD)\n",
    "\n",
    "    def count(self, data, label):\n",
    "        nC, nD = 0, 0\n",
    "        for lbl in data[label]:\n",
    "            if lbl == 0:\n",
    "                nC += 1\n",
    "            else:\n",
    "                nD += 1\n",
    "        return nC, nD\n",
    "\n",
    "    def segmenter(self, data, label, is_random_forest=False, m=0):\n",
    "        \"\"\"\n",
    "        For splits on a feature f with a value v,\n",
    "            left will have samples with f values strictly less than v\n",
    "            right will have samples with f values greater than or equal to v\n",
    "        \"\"\"\n",
    "        if is_random_forest:\n",
    "            if m <= 0:\n",
    "                m = int(sqrt(len(data.axes[1]) - 1))\n",
    "            elif m < 1:\n",
    "                m = int((len(data.axes[1]) - 1) * m)\n",
    "            features = data.drop(label, 1).sample(m, axis=1)\n",
    "        else:\n",
    "            features = data.drop(label, 1).axes[1]\n",
    "\n",
    "        min_entropy, splitf, splitv, spliti = float('inf'), None, None, 0\n",
    "\n",
    "        for f in features:\n",
    "            sorted_data_by_f = data.sort_values(f)\n",
    "\n",
    "            iterv = sorted_data_by_f[f].__iter__()\n",
    "            iterl = sorted_data_by_f[label].__iter__()\n",
    "\n",
    "            nC, nD = self.count(sorted_data_by_f, label)\n",
    "\n",
    "            # keeps track of which value-label pair we're on\n",
    "            v, lbl, i = next(iterv), next(iterl), 0\n",
    "\n",
    "            # keeps track of class counts on LEFT\n",
    "            C, D = 0, 0\n",
    "\n",
    "            # don't check if all data lies on one side, since then this node should be a leaf (base case of train)\n",
    "            beta_iter = sorted_data_by_f.drop_duplicates(subset=f, keep='first')[f].__iter__()\n",
    "            next(beta_iter)\n",
    "\n",
    "            for beta in beta_iter:\n",
    "                try:\n",
    "                    while v != beta:\n",
    "                        if lbl == 0:\n",
    "                            C += 1\n",
    "                        else:\n",
    "                            D += 1\n",
    "                        i += 1\n",
    "                        v, lbl = next(iterv), next(iterl)\n",
    "                except StopIteration:\n",
    "                    continue\n",
    "                entropy = self.impurity(C, D, nC, nD)\n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy, splitf, splitv, spliti = entropy, f, beta, i\n",
    "            # no need to check split on max(beta)+1 since then all elements are on one split (node should be leaf)\n",
    "\n",
    "        if splitf == None:\n",
    "            return None, None, splitf, splitv #, spliti\n",
    "\n",
    "        sorted_data = data.sort_values(splitf)\n",
    "        left = sorted_data.iloc[:spliti]\n",
    "        right = sorted_data.iloc[spliti:]\n",
    "\n",
    "        return left, right, splitf, splitv #, spliti\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "        def grow_tree(train_data, label, depth_limited=float('inf'), is_random_forest=False, m=0):\n",
    "            labels = train_data[label].unique()\n",
    "            if depth_limited == 0 or len(labels) == 1:\n",
    "                return LeafNode(labels[0])\n",
    "\n",
    "            left_data, right_data, split_feature, split_value = self.segmenter(train_data, label, is_random_forest, m)\n",
    "\n",
    "            if left_data is None:\n",
    "                lbl = train_data[label].value_counts().argmax()\n",
    "                return LeafNode(lbl)\n",
    "\n",
    "            left = grow_tree(left_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            right = grow_tree(right_data, label, depth_limited - 1, is_random_forest, m)\n",
    "            return InternalNode(left, right, split_feature, split_value)\n",
    "        self.root = grow_tree(train_data, label, depth_limited, is_random_forest, m)\n",
    "\n",
    "    def predict(self, data, verbose=False):\n",
    "        return self.root.predict(data, verbose)\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n=150):\n",
    "        self.n = n\n",
    "        self.forest = []\n",
    "\n",
    "    def train(self, train_data, label, depth_limited=float('inf'), m=0, bagging=0):\n",
    "        if bagging == 0:\n",
    "             bagging = len(train_data)\n",
    "        for i in range(self.n):\n",
    "            t = DecisionTree()\n",
    "            t.train(train_data.sample(bagging, replace=True), label, depth_limited, True, m)\n",
    "            self.forest.append(t)\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions, count0, count1 = [], 0, 0\n",
    "        for t in self.forest:\n",
    "            predictions.append(t.predict(data))\n",
    "            if predictions[-1] == 0:\n",
    "                count0 += 1\n",
    "            else:\n",
    "                count1 += 1\n",
    "        if count0 > count1:\n",
    "            return 0\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Implementation Details\n",
    "(a) Categorical features were mapped to binary variables as suggested in Appendix 1.a. For the Titanic dataset, missing values of categorical data were replaced with the mode and for continuous features with the mean while for all other datasets missing values were replaced with just the mean.\n",
    "\n",
    "(b) The stopping criteria used was having pure nodes (all samples in a node belonging to the same class) or having an empty child (this would be the left); however, a depth-limited criteria was also implemented and used for random forests.\n",
    "\n",
    "(c) Nothing special was done to speed up training.\n",
    "\n",
    "(d) The `segmenter` method of `DecisionTree` was modified to sample features for `RandomForest`. A `RandomForest` class was created and held a list of `DecisionTree`. Each `DecisionTree` of the list was trained with bagging, and bagging was done in `RandomForest#train`.\n",
    "\n",
    "(e) Nothing out of the ordinary was implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Performance Evaluation\n",
    "Kaggle username: cschon\n",
    "\n",
    "#### Titanic\n",
    "* Decision Tree\n",
    "    * Training: 0.9737\n",
    "    * Validation: 0.7755\n",
    "* Random Forest\n",
    "    * Training: 0.8632\n",
    "    * Validation: 0.8163\n",
    "* Kaggle (Random Forest): \t0.80645\n",
    "\n",
    "#### Census\n",
    "* Decision Tree\n",
    "    * Training: 0.8296\n",
    "    * Validation: 0.8142\n",
    "* Random Forest\n",
    "    * Training: 0.8607\n",
    "    * Validation: 0.8551\n",
    "* Kaggle (Decision Tree): \t0.81338\n",
    "\n",
    "#### Spam\n",
    "* Decision Tree\n",
    "    * Training: 0.7724\n",
    "    * Validation: 0.7722\n",
    "* Random Forest\n",
    "    * Training: 0.8009\n",
    "    * Validation: 0.8084\n",
    "* Kaggle (Decision Tree): 0.76840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(data, label, model, depth_limited=float('inf'), n=None):\n",
    "    shuffled_data = data.sample(frac=1)\n",
    "    tvnum = int(len(shuffled_data) // 20)\n",
    "    vdata = shuffled_data[:tvnum]\n",
    "    tdata = shuffled_data[tvnum:]\n",
    "    \n",
    "    if n == None:\n",
    "        m = model()\n",
    "    else:\n",
    "        m = model(n)\n",
    "    m.train(tdata, label, depth_limited)\n",
    "    return m, vdata, tdata\n",
    "    \n",
    "def evaluate(data, label, model, depth_limited=float('inf'), n=None):\n",
    "    m, vdata, tdata = train(data, label, model, depth_limited, n)\n",
    "\n",
    "    vcorrect = 0\n",
    "    for _, vsample in vdata.iterrows():\n",
    "        if m.predict(vsample) == vsample[label]:\n",
    "            vcorrect += 1\n",
    "            \n",
    "    tcorrect = 0      \n",
    "    for _, tsample in tdata.iterrows():\n",
    "        if m.predict(tsample) == tsample[label]:\n",
    "            tcorrect += 1\n",
    "            \n",
    "    return vcorrect / len(vdata), tcorrect / len(tdata), m\n",
    "\n",
    "def print_evaluate(data, label, model, depth_limited=float('inf')):\n",
    "    v, t, m = evaluate(data, label, model, depth_limited)\n",
    "    print('Training Accuracy: {}\\nValidation Accuracy: {}'.format(t, v))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9736842105263158\n",
      "Validation Accuracy: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "tdt = print_evaluate(ttdata, 'survived', DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8296448790530108\n",
      "Validation Accuracy: 0.8141809290953546\n"
     ]
    }
   ],
   "source": [
    "cdt = print_evaluate(ctdata, 'label', DecisionTree, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.772438601945197\n",
      "Validation Accuracy: 0.7721518987341772\n"
     ]
    }
   ],
   "source": [
    "sdt = print_evaluate(stdata, 'label', DecisionTree, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8631578947368421\n",
      "Validation Accuracy: 0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "trf = print_evaluate(ttdata, 'survived', RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8606536284096757\n",
      "Validation Accuracy: 0.8551344743276283\n"
     ]
    }
   ],
   "source": [
    "crf = print_evaluate(ctdata, 'label', RandomForest, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8008615712572723\n",
      "Validation Accuracy: 0.8084388185654009\n"
     ]
    }
   ],
   "source": [
    "srf = print_evaluate(stdata, 'label', RandomForest, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_trf = RandomForest()\n",
    "kaggle_trf.train(ttdata, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('titanic.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ttestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_trf.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_cdt = DecisionTree()\n",
    "kaggle_cdt.train(ctdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('census.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 1\n",
    "for _, vsample in ctestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_cdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_sdt = DecisionTree()\n",
    "kaggle_sdt.train(stdata, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('spam.csv', 'w')\n",
    "f.write(\"Id,Category\\n\")\n",
    "i = 0\n",
    "for _, vsample in stestdata.iterrows():\n",
    "    f.write(\"{},{}\\n\".format(i, int(kaggle_sdt.predict(vsample))))\n",
    "    i += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Spam Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5(a): Features\n",
    "No other features or feature transformations were used.\n",
    "\n",
    "## Question 5(b): Decision Tree Splits\n",
    "\n",
    "(\"!\") < 1  \n",
    "(\"(\") >= 1  \n",
    "(\"money\") < 1  \n",
    "(\"featured\") < 1  \n",
    "(\"energy\") < 1  \n",
    "(\"$\") < 1  \n",
    "(\"spam\") < 1  \n",
    "(\"bank\") < 2  \n",
    "(\"prescription\") < 1  \n",
    "(\"[\") < 1  \n",
    "Ham (class 0)  \n",
    "\n",
    "(\"!\") >= 1  \n",
    "(\"energy\") < 1  \n",
    "(\"money\") < 1  \n",
    "(\"(\") < 1  \n",
    "(\"!\") < 33  \n",
    "(\"prescription\") < 1  \n",
    "(\"$\") >= 1  \n",
    "(\"volumes\") < 1  \n",
    "(\"&\") < 4  \n",
    "(\"meter\") < 1  \n",
    "Ham (class 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = stdata.sample(10)\n",
    "ham = samples[samples['label'] == 0].iloc[0]\n",
    "spam = samples[samples['label'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0] \n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(ham), '\\n')\n",
    "print(list(spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature !: 0.0 < 1.0 -> left\n",
      "Feature (: 1.0 >= 1.0 -> right\n",
      "Feature money: 0.0 < 1.0 -> left\n",
      "Feature featured: 0.0 < 1.0 -> left\n",
      "Feature energy: 0.0 < 1.0 -> left\n",
      "Feature $: 0.0 < 1.0 -> left\n",
      "Feature spam: 0.0 < 1.0 -> left\n",
      "Feature bank: 0.0 < 2.0 -> left\n",
      "Feature prescription: 0.0 < 1.0 -> left\n",
      "Feature [: 0.0 < 1.0 -> left\n",
      "Leaf(0.0)\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(sdt.predict(ham, True), ham['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature !: 1.0 >= 1.0 -> right\n",
      "Feature energy: 0.0 < 1.0 -> left\n",
      "Feature money: 0.0 < 1.0 -> left\n",
      "Feature (: 0.0 < 1.0 -> left\n",
      "Feature !: 1.0 < 33.0 -> left\n",
      "Feature prescription: 0.0 < 1.0 -> left\n",
      "Feature $: 1.0 >= 1.0 -> right\n",
      "Feature volumes: 0.0 < 1.0 -> left\n",
      "Feature &: 1.0 < 4.0 -> left\n",
      "Feature meter: 0.0 < 1.0 -> left\n",
      "Leaf(1.0)\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(sdt.predict(spam, True), spam['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5(c): Random Forest most common split made at root node of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def root_splits(rf):\n",
    "    root_splits = {}\n",
    "    for t in rf.forest:\n",
    "        pair = (t.root.split_feature, t.root.split_value)\n",
    "        if pair not in root_splits:\n",
    "            root_splits[pair] = 0\n",
    "        root_splits[pair] += 1\n",
    "    \n",
    "    split_ranking = sorted(root_splits.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for s in split_ranking:\n",
    "        print('(\\\"{}\\\"), {} ({} trees)'.format(s[0][0], int(s[0][1]), s[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"money\"), 1 (29 trees)\n",
      "(\"!\"), 1 (20 trees)\n",
      "(\"energy\"), 1 (18 trees)\n",
      "(\"(\"), 1 (17 trees)\n",
      "(\"$\"), 1 (12 trees)\n",
      "(\"featured\"), 1 (10 trees)\n",
      "(\"&\"), 1 (8 trees)\n",
      "(\"prescription\"), 1 (7 trees)\n",
      "(\"meter\"), 1 (7 trees)\n",
      "(\"private\"), 1 (3 trees)\n",
      "(\"volumes\"), 1 (3 trees)\n",
      "(\"pain\"), 1 (3 trees)\n",
      "(\"memo\"), 1 (3 trees)\n",
      "(\";\"), 2 (2 trees)\n",
      "(\"spam\"), 1 (2 trees)\n",
      "(\";\"), 4 (2 trees)\n",
      "(\"creative\"), 1 (2 trees)\n",
      "(\"drug\"), 1 (1 trees)\n",
      "(\"differ\"), 1 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "root_splits(srf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 6: Census Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6(a): Features\n",
    "Other than transforming categorical features to binary variables, no other features or feature transformations were used.  \n",
    "\n",
    "## Question 6(b): Decision Tree Splits\n",
    "\n",
    "(\"marital-status=Married-civ-spouse\") < 1  \n",
    "(\"capital-gain\") < 7262  \n",
    "(\"education-num\") < 13  \n",
    "(\"age\") >= 27  \n",
    "(\"hours-per-week\") < 41  \n",
    "(\"capital-loss\") < 2231  \n",
    "(\"occupation=Prof-specialty\") < 1  \n",
    "(\"occupation=Exec-managerial\") < 1  \n",
    "(\"sex=Female\") < 1  \n",
    "(\"age\") < 42  \n",
    "[< $50k] (class 0)\n",
    "\n",
    "(\"marital-status=Married-civ-spouse\") >= 1  \n",
    "(\"education-num\") >= 12  \n",
    "(\"capital-gain\") < 5178  \n",
    "(\"capital-loss\") < 1825  \n",
    "(\"hours-per-week\") >= 31  \n",
    "(\"age\") < 34  \n",
    "(\"age\") >= 28  \n",
    "(\"occupation=Exec-managerial\") < 1  \n",
    "(\"education=Assoc-acdm\") < 1  \n",
    "(\"native-country=United-States\") >= 1  \n",
    "[>= $50k] (class 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ctdata.sample(10)\n",
    "poor = samples[samples['label'] == 0].iloc[0]\n",
    "rich = samples[samples['label'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature marital-status=Married-civ-spouse: 0.0 < 1.0 -> left\n",
      "Feature capital-gain: 0.0 < 7262.0 -> left\n",
      "Feature education-num: 10.0 < 13.0 -> left\n",
      "Feature age: 30.0 >= 27.0 -> right\n",
      "Feature hours-per-week: 40.0 < 41.0 -> left\n",
      "Feature capital-loss: 0.0 < 2231.0 -> left\n",
      "Feature occupation=Prof-specialty: 0.0 < 1.0 -> left\n",
      "Feature occupation=Exec-managerial: 0.0 < 1.0 -> left\n",
      "Feature sex=Female: 0.0 < 1.0 -> left\n",
      "Feature age: 30.0 < 42.0 -> left\n",
      "Leaf(0.0)\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(cdt.predict(poor, True), poor['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature marital-status=Married-civ-spouse: 1.0 >= 1.0 -> right\n",
      "Feature education-num: 13.0 >= 12.0 -> right\n",
      "Feature capital-gain: 0.0 < 5178.0 -> left\n",
      "Feature capital-loss: 0.0 < 1825.0 -> left\n",
      "Feature hours-per-week: 40.0 >= 31.0 -> right\n",
      "Feature age: 31.0 < 34.0 -> left\n",
      "Feature age: 31.0 >= 28.0 -> right\n",
      "Feature occupation=Exec-managerial: 0.0 < 1.0 -> left\n",
      "Feature education=Assoc-acdm: 0.0 < 1.0 -> left\n",
      "Feature native-country=United-States: 1.0 >= 1.0 -> right\n",
      "Leaf(1.0)\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(cdt.predict(rich, True), rich['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6(c): Random Forest most common split made at root node of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"marital-status=Married-civ-spouse\"), 1 (12 trees)\n",
      "(\"relationship=Husband\"), 1 (12 trees)\n",
      "(\"education-num\"), 13 (11 trees)\n",
      "(\"marital-status=Never-married\"), 1 (10 trees)\n",
      "(\"relationship=Own-child\"), 1 (9 trees)\n",
      "(\"relationship=Not-in-family\"), 1 (9 trees)\n",
      "(\"capital-gain\"), 7298 (9 trees)\n",
      "(\"sex=Male\"), 1 (7 trees)\n",
      "(\"age\"), 28 (7 trees)\n",
      "(\"occupation=Other-service\"), 1 (7 trees)\n",
      "(\"sex=Female\"), 1 (6 trees)\n",
      "(\"education=Masters\"), 1 (5 trees)\n",
      "(\"age\"), 29 (5 trees)\n",
      "(\"education=Bachelors\"), 1 (5 trees)\n",
      "(\"education=Doctorate\"), 1 (4 trees)\n",
      "(\"marital-status=Divorced\"), 1 (4 trees)\n",
      "(\"relationship=Unmarried\"), 1 (3 trees)\n",
      "(\"capital-loss\"), 1825 (3 trees)\n",
      "(\"capital-gain\"), 5178 (3 trees)\n",
      "(\"occupation=Prof-specialty\"), 1 (3 trees)\n",
      "(\"hours-per-week\"), 42 (2 trees)\n",
      "(\"occupation=Adm-clerical\"), 1 (2 trees)\n",
      "(\"hours-per-week\"), 41 (2 trees)\n",
      "(\"marital-status=Separated\"), 1 (1 trees)\n",
      "(\"education=10th\"), 1 (1 trees)\n",
      "(\"occupation=Exec-managerial\"), 1 (1 trees)\n",
      "(\"education=HS-grad\"), 1 (1 trees)\n",
      "(\"education-num\"), 12 (1 trees)\n",
      "(\"education=Prof-school\"), 1 (1 trees)\n",
      "(\"relationship=Wife\"), 1 (1 trees)\n",
      "(\"occupation=Farming-fishing\"), 1 (1 trees)\n",
      "(\"workclass=Self-emp-inc\"), 1 (1 trees)\n",
      "(\"race=White\"), 1 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "root_splits(crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6(d) Depth Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    shuffled_data = data.sample(frac=1)\n",
    "    vdata = shuffled_data[:20]\n",
    "    tdata = shuffled_data[20:100]\n",
    "    return tdata, vdata\n",
    "\n",
    "def train(data, label, model, depth_limited=float('inf'), n=None):\n",
    "    if n == None:\n",
    "        m = model()\n",
    "    else:\n",
    "        m = model(n)\n",
    "    m.train(tdata, label, depth_limited)\n",
    "    return m\n",
    "    \n",
    "def evaluate(tdata, vdata, label, model, depth_limited=float('inf'), n=None):\n",
    "    m = train(tdata, label, model, depth_limited, n)\n",
    "\n",
    "    vcorrect = 0\n",
    "    for _, vsample in vdata.iterrows():\n",
    "        if m.predict(vsample) == vsample[label]:\n",
    "            vcorrect += 1\n",
    "            \n",
    "    tcorrect = 0      \n",
    "    for _, tsample in tdata.iterrows():\n",
    "        if m.predict(tsample) == tsample[label]:\n",
    "            tcorrect += 1\n",
    "            \n",
    "    return vcorrect / len(vdata), tcorrect / len(tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdata, vdata = data_split(ctdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for depth in range(1, 41):\n",
    "    vcorrect, tcorrect = evaluate(tdata, vdata, 'label', DecisionTree, depth)\n",
    "    accuracies.append(vcorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGHCAYAAAD/QltcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNranT0TbVSQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1255fe1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [0] + accuracies\n",
    "plt.xlim([0, 40])\n",
    "plt.ylim([0, 1])\n",
    "# plt.xlim(xmin=1) \n",
    "plt.plot(accuracies)\n",
    "plt.title('Validation Accuracies for Tuning Depth')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth 7 and beyond had the highest validation accuracy. This is probably due to the small training set, which may have been completely separated by depth 7. Thus, depths 7 and beyond may have overfit on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7: Titanic Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shallow_tdt = DecisionTree()\n",
    "shallow_tdt.train(ttdata, 'survived', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalNode(sex=female, 1.0)\n",
      "InternalNode(age, 10.0)\n",
      "InternalNode(pclass, 3.0)\n",
      "InternalNode(sibsp, 3.0)\n",
      "InternalNode(pclass, 2.0)\n",
      "InternalNode(embarked=S, 1.0)\n",
      "InternalNode(fare, 23.45)\n",
      "Leaf(1.0)\n",
      "Leaf(0.0)\n",
      "Leaf(1.0)\n",
      "Leaf(0.0)\n",
      "Leaf(1.0)\n",
      "Leaf(1.0)\n",
      "Leaf(1.0)\n",
      "Leaf(0.0)\n"
     ]
    }
   ],
   "source": [
    "q = []\n",
    "q.append(shallow_tdt.root)\n",
    "while len(q) > 0:\n",
    "    n = q.pop(0)\n",
    "    print(n)\n",
    "    if not n.is_leaf():\n",
    "        q.append(n.left)\n",
    "        q.append(n.right)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
